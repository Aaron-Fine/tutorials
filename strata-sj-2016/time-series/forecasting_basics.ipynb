{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load and inspect the data: daily global earthquakes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the main dataset: Feb. 2, 2013 - Mar. 15, 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import graphlab as gl\n",
    "\n",
    "daily_stats = gl.load_timeseries('working_data/global_daily_stats.ts')\n",
    "\n",
    "print \"Number of rows:\", len(daily_stats)\n",
    "print \"Start:\", daily_stats.min_time\n",
    "print \"End:\", daily_stats.max_time\n",
    "daily_stats.print_rows(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the recent data: Mar. 16, 2016 - Mar. 22, 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first point in this dataset is our forecasting goal. Pretend it's March 15, and we don't know the count of earthquakes for March 16th."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "daily_update = gl.load_timeseries('working_data/global_daily_update.ts')\n",
    "daily_update.print_rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the data with GraphLab Canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "daily_stats.to_sframe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the data with matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(daily_stats['time'], daily_stats['count'], color='dodgerblue')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Number of earthquakes')\n",
    "fig.autofmt_xdate()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. A naive baseline: the grand mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baseline_forecast = daily_stats['count'].mean()\n",
    "\n",
    "print baseline_forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. The autoregressive model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create lagged features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "daily_stats['lag1_count'] = daily_stats.shift(1)['count']\n",
    "daily_stats['lag2_count'] = daily_stats.shift(2)['count']\n",
    "\n",
    "daily_stats.print_rows(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_counts = daily_stats[2:].to_sframe()\n",
    "\n",
    "ar_model = gl.linear_regression.create(train_counts, target='count',\n",
    "                                        features=['lag1_count', 'lag2_count'],\n",
    "                                        l2_penalty=0., validation_set=None,\n",
    "                                        verbose=False)\n",
    "\n",
    "print ar_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_counts.tail(5).print_rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a forecast from the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Construct the input dataset first.\n",
    "sf_forecast = gl.SFrame({'lag1_count': [daily_stats['count'][-1]],\n",
    "                         'lag2_count': [daily_stats['count'][-2]]})\n",
    "\n",
    "## Compute the model's forecast\n",
    "ar_forecast = ar_model.predict(sf_forecast)\n",
    "print ar_forecast[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. The gradient-boosted trees model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the timestamp into parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "date_parts = daily_stats.index.split_datetime(column_name_prefix='date',\n",
    "                                        limit=['year', 'month', 'day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create lags for *observed* features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To forecast tomorrow's earthqauke count:\n",
    "- we do know what the date will be, so no need to lag,\n",
    "- we don't know what the max and average magnitude will be, so we need to lag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "daily_stats['lag1_avg_mag'] = daily_stats.shift(1)['avg_mag']\n",
    "daily_stats['lag1_max_mag'] = daily_stats.shift(1)['max_mag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sf_train = daily_stats.to_sframe()\n",
    "sf_train = sf_train.add_columns(date_parts)\n",
    "\n",
    "sf_train.print_rows(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_list = ['lag1_avg_mag', 'lag1_max_mag', 'lag1_count',\n",
    "                'date.year', 'date.month', 'date.day']\n",
    "\n",
    "# Remove the row with no lagged features.\n",
    "sf_train = sf_train[1:]\n",
    "\n",
    "gbt_model = gl.boosted_trees_regression.create(sf_train, target='count',\n",
    "                                               features=feature_list,\n",
    "                                               max_iterations=20,\n",
    "                                               validation_set=None,\n",
    "                                               verbose=False)\n",
    "\n",
    "print gbt_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the model's forecast "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Prepend the last couple rows of the training data.\n",
    "ts_forecast = daily_stats[daily_update.column_names()][-2:].union(daily_update)\n",
    "\n",
    "## Create the lagged features.\n",
    "ts_forecast['lag1_avg_mag'] = ts_forecast.shift(1)['avg_mag']\n",
    "ts_forecast['lag1_max_mag'] = ts_forecast.shift(1)['max_mag']\n",
    "ts_forecast['lag1_count'] = ts_forecast.shift(1)['count']\n",
    "\n",
    "## Split the timestamp into date parts.\n",
    "new_date_parts = ts_forecast.index.split_datetime(column_name_prefix='date',\n",
    "                                        limit=['year', 'month', 'day'])\n",
    "\n",
    "## Add the date parts to the dataset.\n",
    "sf_forecast = ts_forecast.to_sframe().add_columns(new_date_parts)\n",
    "\n",
    "sf_forecast.print_rows(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbt_forecast = gbt_model.predict(sf_forecast)\n",
    "gbt_forecast[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. And the winner is... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Actual value for March 16:\", daily_update['count'][0]\n",
    "print \"\\nBaseline forecast:\", baseline_forecast\n",
    "print \"AR model forecast:\", ar_forecast[0]\n",
    "print \"GBT forecast:\", gbt_forecast[2], \"\\t(*** winner ***)\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
