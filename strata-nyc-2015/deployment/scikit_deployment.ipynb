{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction to ML Deployment\n",
    "==================\n",
    "\n",
    "Deploying models created using python in a Turi Predictive Service is very easy. This notebook walks you through the step-by-step process. \n",
    "\n",
    "<img src='images/predictive_services_overview.png'></img>\n",
    "\n",
    "-----------------------\n",
    "\n",
    "Deployment Steps\n",
    "=========\n",
    "The notebook has three sections: \n",
    "\n",
    "1. <a href='#cpo'>Create a model</a>\n",
    "2. <a href='#create'>Create a predictive service</a>\n",
    "3. <a href='#query'>Query the model</a>\n",
    "\n",
    "If you are deploying a model in an existing Predictive Service instance you can go to step (2) directly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create a model <a id='cpo'></a>\n",
    "\n",
    "Let's train a simple random forest model and deploy it in the Predictive Service.\n",
    "\n",
    "<img src=\"images/left.png\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=10)\n",
    "model = model.fit(iris['data'], iris['target'])\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can expose the trained model as a REST endpoint. This will allow other applications to consume the predictions from the model.  \n",
    "\n",
    "In order to do that, we wrap the model object in a Python function and add it to the Predictive Service. In the function you may add your own logic for transform input to the model, ensemble different models or manipulate output before returning. Checkout out [user guide](https://turi.com/learn/userguide/#Deployment) for more details.\n",
    "\n",
    "The result of the function needs to be  a **JSON serializable** object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(x):\n",
    "    prediction = model.predict(x)\n",
    "\n",
    "    # convert into a json serializable value\n",
    "    return list(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a Predictive Service (One time) <a id='create'></a>\n",
    "\n",
    "This section shows you how to deploy a Predictive Service to EC2. The EC2 instances used by the Predictive Service will be launched in your own AWS account, so you will be responsible for the cost. \n",
    "\n",
    "<img src=\"images/middle.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a Predictive Service in Amazon AWS, we first configure the EC2 Config object, which contains the configuration parameters required for launching a Predictive Service cluster in EC2. These fields are optional and include the region, instance type, CIDR rules etc. Predictive Service uses this configuration for service creation.\n",
    "\n",
    "Having configured our EC2 Config object, we're ready to launch a Predictive Service Deployment, There are a few aspects of the Predictive Service that can be customized:\n",
    "* Number of nodes in the service - By default the number of hosts (`num_hosts`) is 1. To obtain good cache utility and high availability, we recommended setting num_hosts to at least 3.\n",
    "* State path to persist service state and service logs. This is a s3 location. \n",
    "* Port to be used by the server.\n",
    "* Other settings, such as SSL credentials etc.\n",
    "\n",
    "The following code snippet shows you how to create a Predictive Service. You will have to replace the ps_state_path and credentials for your Predictive Service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import graphlab as gl\n",
    "\n",
    "# Replace with your path.\n",
    "ps_state_path = 's3://<your-bucket-name>/predictive_service/ps'\n",
    "\n",
    "# Set your AWS credentials.\n",
    "gl.aws.set_credentials(<key>, <secret>)\n",
    "\n",
    "# Create an EC2 config\n",
    "ec2_config = gl.deploy.Ec2Config()\n",
    "\n",
    "# Launch a predictive service\n",
    "ps = gl.deploy.predictive_service.create(name = 'sklearn-predictive-service', \n",
    "              ec2_config = ec2_config, state_path = ps_state_path, num_hosts = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load an already created service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] Overwritting existing Predictive Service \"demolab-one-six\" in local session.\n"
     ]
    }
   ],
   "source": [
    "import graphlab as gl\n",
    "ps = gl.deploy.predictive_service.load('s3://gl-demo-usw2/predictive_service/demolab/ps-1.6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                  : demolab-one-six\n",
       "State Path            : s3://gl-demo-usw2/predictive_service/demolab/ps-1.6\n",
       "Description           : None\n",
       "API Key               : b437e588-0f2b-45e1-81c8-ce3acfa81ade\n",
       "CORS origin           : *\n",
       "Global Cache State    : enabled\n",
       "Load Balancer DNS Name: demolab-one-six-2015364754.us-west-2.elb.amazonaws.com\n",
       "\n",
       "Deployed endpoints:\n",
       "\tname: freshdress_kw_search, version: 3, type: alias, cache: disabled, description: Alias for freshdress_kw_search_model\n",
       "\tname: yelp_sentiment_most_extreme_for_place, version: 2, type: model, cache: enabled, description: \n",
       "\tname: classify-sklearn, version: 2, type: model, cache: enabled, description: \n",
       "\tname: freshdress_more_like_image_bw, version: 1, type: model, cache: enabled, description: \n",
       "\tname: freshdress_kw_search_model, version: 2, type: model, cache: enabled, description: \n",
       "\tname: composite_recommender_query, version: 1, type: model, cache: disabled, description: \n",
       "\tname: freshdress_describe, version: 2, type: alias, cache: disabled, description: Alias for freshdress_describe_image_basic\n",
       "\tname: freshdress_more_like_image_bow, version: 3, type: model, cache: enabled, description: \n",
       "\tname: yelp_sentiment_predict_text, version: 2, type: model, cache: enabled, description: \n",
       "\tname: freshdress_describe_image_basic, version: 1, type: model, cache: enabled, description: \n",
       "\tname: freshdress_more_like_image_color, version: 1, type: model, cache: enabled, description: \n",
       "\tname: freshdress_more_like_image, version: 5, type: alias, cache: disabled, description: Alias for freshdress_more_like_image_tfidf\n",
       "\tname: yelp_sentiment_most_extreme, version: 2, type: model, cache: enabled, description: \n",
       "\tname: freshdress_more_like_image_tfidf, version: 1, type: model, cache: enabled, description: \n",
       "\tname: composite_recommender_explanation, version: 1, type: model, cache: disabled, description: \n",
       "\tname: yelp_sentiment_summary, version: 2, type: model, cache: enabled, description: \n",
       "\n",
       "No Pending changes."
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Endpoint 'classify-sklearn' is updated. Use apply_changes to deploy all pending changes, or continue other modification.\n"
     ]
    }
   ],
   "source": [
    "# ps.add('classify-sklearn', classify) (If done for the first time)\n",
    "ps.update('classify-sklearn', classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] There are no pending changes. No action is taken.\n"
     ]
    }
   ],
   "source": [
    "ps.apply_changes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the model <a id='query'></a>\n",
    "\n",
    "You may do a test query before really deploying it to production. This will help detect errors in the function before deploying it the Predictive Service. \n",
    "\n",
    "<img src=\"images/right.png\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Input data serializable.\n",
      "[INFO] Trying to serve classify-sklearn\n",
      "[INFO] Query results serializable.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{u'response': [0],\n",
       " u'uuid': u'88947cb8-4646-489d-8360-81ce1d54004e',\n",
       " u'version': 1}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.test_query('classify-sklearn', x=[5.1,  3.5,  1.4,  0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us query the real service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'from_cache': True,\n",
       " u'model': u'classify-sklearn',\n",
       " u'response': [0],\n",
       " u'uuid': u'8afd2f01-6d37-4fd0-8788-5141f92459dd',\n",
       " u'version': 2}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test query to make sure the model works fine\n",
    "ps.query('classify-sklearn', x=[5.1,  3.5,  1.4,  0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query from external applications via REST\n",
    "\n",
    "Now other applications can interact with our model! In the next section we will illustrate how to consume the model. We can also  use other APIs like ps.update() to update a mode, ps.remove() to remove a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model query is exposed through REST API. The path is:\n",
    "\n",
    "    http(s)://<your-ps-endpoint>/data/<model-name>\n",
    "    \n",
    "And the payload is a JSON serialized string in the following format:\n",
    "\n",
    "    {\"api_key\": <api key>,\n",
    "     \"data\": <data-passed-to-custom-query>}\n",
    "\n",
    "Here the 'api key' may be obtained through ps.api_key, and data is the actual data passed to the custom predictive object in the Predictive Service. It will be passed to the query using **kwargs format\n",
    "\n",
    "Here is a sample curl command to query your model:\n",
    "\n",
    "    curl -X POST -d '{\"api_key\":\"b437e588-0f2b-45e1-81c8-ce3acfa81ade\", \"data\":{\"x\":[5.1,  3.5,  1.4,  0.2]}}' http://demolab-one-six-2015364754.us-west-2.elb.amazonaws.com/query/classify-sklearn\n",
    "   \n",
    "    \n",
    "You can also query though Python using the **requests module**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query through Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "def restful_query(x):\n",
    "    headers = {'content-type': 'application/json'}\n",
    "    payload = {'api_key':'b437e588-0f2b-45e1-81c8-ce3acfa81ade', \"data\":{\"x\": x}}\n",
    "    end_point = 'http://demolab-one-six-2015364754.us-west-2.elb.amazonaws.com/query/classify-sklearn'\n",
    "    return requests.post(end_point, json.dumps(payload), headers=headers).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'from_cache': True,\n",
       " u'model': u'classify-sklearn',\n",
       " u'response': [0],\n",
       " u'uuid': u'ea1a4314-4795-4ca6-9822-70774e4fdafd',\n",
       " u'version': 2}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restful_query([5.1,  3.5,  1.4,  0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'from_cache': False,\n",
       " u'model': u'classify-sklearn',\n",
       " u'response': [0],\n",
       " u'uuid': u'a96dc4e6-b3de-4e72-9526-e12174ea58af',\n",
       " u'version': 2}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restful_query([5.1,  3.5,  1.4,  0.3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
