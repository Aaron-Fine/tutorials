{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction to ML Deployment\n",
    "==================\n",
    "\n",
    "Deploying models created using python in a Turi Predictive Service is very easy. This notebook walks you through the step-by-step process. \n",
    "\n",
    "<img src='images/predictive_services_overview.png'></img>\n",
    "\n",
    "-----------------------\n",
    "\n",
    "Deployment Steps\n",
    "=========\n",
    "The notebook has three sections: \n",
    "\n",
    "1. <a href='#cpo'>Create a model</a>\n",
    "2. <a href='#create'>Create a predictive service</a>\n",
    "3. <a href='#query'>Query the model</a>\n",
    "\n",
    "If you are deploying a model in an existing Predictive Service instance you can go to step (2) directly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create a model <a id='cpo'></a>\n",
    "\n",
    "Let's train a simple pattern mining model\n",
    "\n",
    "<img src=\"images/left.png\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] This commercial license of GraphLab Create is assigned to engr@turi.com.\n",
      "\n",
      "[INFO] Start server at: ipc:///tmp/graphlab_server-58453 - Server binary: /Users/srikris/.graphlab/anaconda/lib/python2.7/site-packages/graphlab/unity_server - Server log: /tmp/graphlab_server_1445977952.log\n",
      "[INFO] GraphLab Server Version: 1.6.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Class                         : FrequentPatternMiner\n",
       "\n",
       "Model fields\n",
       "------------\n",
       "Min support                   : 1\n",
       "Max patterns                  : 100\n",
       "Min pattern length            : 2\n",
       "\n",
       "Most frequent patterns\n",
       "----------------------\n",
       "['CherryTart', 'ApricotDanish']: 3209\n",
       "['TuileCookie', 'MarzipanCookie']: 3023\n",
       "['ChocolateCake', 'ChocolateCoffee']: 2652\n",
       "['CherryTart', 'OperaCake']   : 2625\n",
       "['GongolaisCookie', 'TruffleCake']: 2620\n",
       "['StrawberryCake', 'NapoleonCake']: 2615\n",
       "['ApricotDanish', 'OperaCake']: 2604\n",
       "['ApricotCroissant', 'BlueberryTart']: 2599\n",
       "['OrangeJuice', 'CheeseCroissant']: 2575\n",
       "['CherryTart', 'ApricotDanish', 'OperaCake']: 2487"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In order to run this code, you need an already trianed model (see the accompanying notebook)\n",
    "import graphlab as gl\n",
    "model = gl.load_model('pattern_mining_model.gl')\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can expose the trained model as a REST endpoint. This will allow other applications to consume the predictions from the model.  \n",
    "\n",
    "In order to do that, we wrap the model object in a Python function and add it to the Predictive Service. In the function you may add your own logic for transform input to the model, ensemble different models or manipulate output before returning. Checkout out [user guide](http://turi.com/learn/userguide/#Deployment) for more details.\n",
    "\n",
    "The result of the function needs to be  a **JSON serializable** object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    # Construct an SFrame\n",
    "    sf = gl.SFrame(x)\n",
    "\n",
    "    # Add your own business logic here    \n",
    "    \n",
    "    # Call the predict method on the model.\n",
    "    predictions = model.predict(sf)\n",
    "    return predictions['prediction']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a Predictive Service (One time) <a id='create'></a>\n",
    "\n",
    "This section shows you how to deploy a Predictive Service to EC2. The EC2 instances used by the Predictive Service will be launched in your own AWS account, so you will be responsible for the cost. \n",
    "\n",
    "<img src=\"images/middle.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a Predictive Service in Amazon AWS, we first configure the EC2 Config object, which contains the configuration parameters required for launching a Predictive Service cluster in EC2. These fields are optional and include the region, instance type, CIDR rules etc. Predictive Service uses this configuration for service creation.\n",
    "\n",
    "Having configured our EC2 Config object, we're ready to launch a Predictive Service Deployment, There are a few aspects of the Predictive Service that can be customized:\n",
    "* Number of nodes in the service - By default the number of hosts (`num_hosts`) is 1. To obtain good cache utility and high availability, we recommended setting num_hosts to at least 3.\n",
    "* State path to persist service state and service logs. This is a s3 location. \n",
    "* Port to be used by the server.\n",
    "* Other settings, such as SSL credentials etc.\n",
    "\n",
    "The following code snippet shows you how to create a Predictive Service. You will have to replace the ps_state_path and credentials for your Predictive Service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import graphlab as gl\n",
    "\n",
    "# Replace with your path.\n",
    "ps_state_path = 's3://<your-bucket-name>/predictive_service/ps'\n",
    "\n",
    "# Set your AWS credentials.\n",
    "gl.aws.set_credentials(<key>, <secret>)\n",
    "\n",
    "# Create an EC2 config\n",
    "ec2_config = gl.deploy.Ec2Config()\n",
    "\n",
    "# Launch a predictive service\n",
    "ps = gl.deploy.predictive_service.create(name = 'sklearn-predictive-service', \n",
    "              ec2_config = ec2_config, state_path = ps_state_path, num_hosts = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load an already created service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] Overwritting existing Predictive Service \"demolab-one-six\" in local session.\n"
     ]
    }
   ],
   "source": [
    "import graphlab as gl\n",
    "ps = gl.deploy.predictive_service.load('s3://gl-demo-usw2/predictive_service/demolab/ps-1.6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                  : demolab-one-six\n",
       "State Path            : s3://gl-demo-usw2/predictive_service/demolab/ps-1.6\n",
       "Description           : Demo Predictive Service for version 1.6\n",
       "API Key               : b437e588-0f2b-45e1-81c8-ce3acfa81ade\n",
       "CORS origin           : *\n",
       "Global Cache State    : enabled\n",
       "Load Balancer DNS Name: demolab-one-six-2015364754.us-west-2.elb.amazonaws.com\n",
       "\n",
       "Deployed endpoints:\n",
       "\tname: freshdress_kw_search, version: 4, type: alias, cache: disabled, description: Alias for freshdress_kw_search_model\n",
       "\tname: freshdress_kw_search_model, version: 2, type: model, cache: enabled, description: \n",
       "\tname: stratanow_speaker, version: 1, type: model, cache: enabled, description: \n",
       "\tname: composite_recommender_query, version: 3, type: model, cache: disabled, description: \n",
       "\tname: freshdress_more_like_image_bow, version: 4, type: model, cache: enabled, description: \n",
       "\tname: credit_prediction, version: 2, type: model, cache: enabled, description: \n",
       "\tname: get_ct_bks, version: 1, type: model, cache: enabled, description: \n",
       "\tname: stratanow_item_sim, version: 1, type: model, cache: enabled, description: \n",
       "\tname: dress_similar, version: 1, type: model, cache: enabled, description: \n",
       "\tname: composite_recommender_explanation, version: 3, type: model, cache: disabled, description: \n",
       "\tname: funny, version: 1, type: model, cache: enabled, description: \n",
       "\tname: pattern-mining, version: 5, type: model, cache: enabled, description: \n",
       "\tname: freshdress_debug_model, version: 1, type: model, cache: enabled, description: \n",
       "\tname: yelp_sentiment_most_extreme, version: 3, type: model, cache: enabled, description: \n",
       "\tname: mahesh_recommender, version: 1, type: model, cache: enabled, description: \n",
       "\tname: swathi_recommender, version: 1, type: model, cache: enabled, description: \n",
       "\tname: freshdress_more_like_image_tfidf, version: 2, type: model, cache: enabled, description: \n",
       "\tname: get_ab_bks, version: 1, type: model, cache: enabled, description: \n",
       "\tname: get_wei, version: 1, type: model, cache: enabled, description: \n",
       "\tname: freshdress_describe, version: 3, type: alias, cache: disabled, description: Alias for freshdress_describe_image_basic\n",
       "\tname: is_this_a_likely_sale, version: 1, type: model, cache: enabled, description: \n",
       "\tname: yelp_sentiment_predict_text, version: 3, type: model, cache: enabled, description: \n",
       "\tname: get_wb_bks, version: 1, type: model, cache: enabled, description: \n",
       "\tname: freshdress_more_like_image_color, version: 5, type: model, cache: enabled, description: \n",
       "\tname: simi_recommender, version: 1, type: model, cache: enabled, description: \n",
       "\tname: freshdress_more_like_image_bw, version: 5, type: model, cache: enabled, description: \n",
       "\tname: get_basis, version: 1, type: model, cache: enabled, description: \n",
       "\tname: yelp_sentiment_summary, version: 3, type: model, cache: enabled, description: \n",
       "\tname: book_recommender, version: 3, type: model, cache: enabled, description: \n",
       "\tname: yelp_sentiment_most_extreme_for_place, version: 3, type: model, cache: enabled, description: \n",
       "\tname: freshdress_more_like_image_avg_color, version: 2, type: model, cache: enabled, description: \n",
       "\tname: classify-sklearn, version: 4, type: model, cache: enabled, description: \n",
       "\tname: freshdress_more_like_image, version: 29, type: alias, cache: disabled, description: Alias for freshdress_more_like_image_bw\n",
       "\tname: get_umang, version: 2, type: model, cache: enabled, description: \n",
       "\tname: get_books_2, version: 2, type: model, cache: enabled, description: \n",
       "\tname: house_similar, version: 1, type: model, cache: enabled, description: \n",
       "\tname: nathan_recommender, version: 1, type: model, cache: enabled, description: \n",
       "\tname: stratanow_list_page, version: 1, type: model, cache: enabled, description: \n",
       "\tname: krishna_recommender, version: 1, type: model, cache: enabled, description: \n",
       "\tname: freshdress_describe_image_basic, version: 1, type: model, cache: enabled, description: \n",
       "\n",
       "No Pending changes."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Endpoint 'pattern-mining' is updated. Use apply_changes to deploy all pending changes, or continue other modification.\n"
     ]
    }
   ],
   "source": [
    "# ps.add('pattern-mining', predict) (When you add this for the first time)\n",
    "ps.update('pattern-mining', predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Uploading local path /var/folders/9h/1m96s7vn5z72cxt_q7g9p86h0000gn/T/predictive_object_KTxfse to s3 path: s3://gl-demo-usw2/predictive_service/demolab/ps-1.6/predictive_objects/pattern-mining/6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ../../../../../../var/folders/9h/1m96s7vn5z72cxt_q7g9p86h0000gn/T/predictive_object_KTxfse/d7c43331-ffdf-4089-b33c-e0cb57b6c91e/m_249b4896e38b5f42/objects.bin to s3://gl-demo-usw2/predictive_service/demolab/ps-1.6/predictive_objects/pattern-mining/6/d7c43331-ffdf-4089-b33c-e0cb57b6c91e/m_249b4896e38b5f42/objects.bin\n",
      "upload: ../../../../../../var/folders/9h/1m96s7vn5z72cxt_q7g9p86h0000gn/T/predictive_object_KTxfse/d7c43331-ffdf-4089-b33c-e0cb57b6c91e/m_249b4896e38b5f42/m_4dd4eeb7c6c1758e.frame_idx to s3://gl-demo-usw2/predictive_service/demolab/ps-1.6/predictive_objects/pattern-mining/6/d7c43331-ffdf-4089-b33c-e0cb57b6c91e/m_249b4896e38b5f42/m_4dd4eeb7c6c1758e.frame_idx\n",
      "upload: ../../../../../../var/folders/9h/1m96s7vn5z72cxt_q7g9p86h0000gn/T/predictive_object_KTxfse/d7c43331-ffdf-4089-b33c-e0cb57b6c91e/m_25d429e4f3ecd1fb.sidx to s3://gl-demo-usw2/predictive_service/demolab/ps-1.6/predictive_objects/pattern-mining/6/d7c43331-ffdf-4089-b33c-e0cb57b6c91e/m_25d429e4f3ecd1fb.sidx\n",
      "upload: ../../../../../../var/folders/9h/1m96s7vn5z72cxt_q7g9p86h0000gn/T/predictive_object_KTxfse/d7c43331-ffdf-4089-b33c-e0cb57b6c91e/m_249b4896e38b5f42/dir_archive.ini to s3://gl-demo-usw2/predictive_service/demolab/ps-1.6/predictive_objects/pattern-mining/6/d7c43331-ffdf-4089-b33c-e0cb57b6c91e/m_249b4896e38b5f42/dir_archive.ini\n",
      "upload: ../../../../../../var/folders/9h/1m96s7vn5z72cxt_q7g9p86h0000gn/T/predictive_object_KTxfse/d7c43331-ffdf-4089-b33c-e0cb57b6c91e/m_547fd4ded584a8dd/dir_archive.ini to s3://gl-demo-usw2/predictive_service/demolab/ps-1.6/predictive_objects/pattern-mining/6/d7c43331-ffdf-4089-b33c-e0cb57b6c91e/m_547fd4ded584a8dd/dir_archive.ini\n",
      "upload: ../../../../../../var/folders/9h/1m96s7vn5z72cxt_q7g9p86h0000gn/T/predictive_object_KTxfse/d7c43331-ffdf-4089-b33c-e0cb57b6c91e/m_249b4896e38b5f42/m_4dd4eeb7c6c1758e.0000 to s3://gl-demo-usw2/predictive_service/demolab/ps-1.6/predictive_objects/pattern-mining/6/d7c43331-ffdf-4089-b33c-e0cb57b6c91e/m_249b4896e38b5f42/m_4dd4eeb7c6c1758e.0000\n",
      "upload: ../../../../../../var/folders/9h/1m96s7vn5z72cxt_q7g9p86h0000gn/T/predictive_object_KTxfse/d7c43331-ffdf-4089-b33c-e0cb57b6c91e/m_249b4896e38b5f42/m_4dd4eeb7c6c1758e.sidx to s3://gl-demo-usw2/predictive_service/demolab/ps-1.6/predictive_objects/pattern-mining/6/d7c43331-ffdf-4089-b33c-e0cb57b6c91e/m_249b4896e38b5f42/m_4dd4eeb7c6c1758e.sidx\n",
      "upload: ../../../../../../var/folders/9h/1m96s7vn5z72cxt_q7g9p86h0000gn/T/predictive_object_KTxfse/d7c43331-ffdf-4089-b33c-e0cb57b6c91e/dir_archive.ini to s3://gl-demo-usw2/predictive_service/demolab/ps-1.6/predictive_objects/pattern-mining/6/d7c43331-ffdf-4089-b33c-e0cb57b6c91e/dir_archive.ini\n",
      "upload: ../../../../../../var/folders/9h/1m96s7vn5z72cxt_q7g9p86h0000gn/T/predictive_object_KTxfse/d7c43331-ffdf-4089-b33c-e0cb57b6c91e/m_25d429e4f3ecd1fb.0000 to s3://gl-demo-usw2/predictive_service/demolab/ps-1.6/predictive_objects/pattern-mining/6/d7c43331-ffdf-4089-b33c-e0cb57b6c91e/m_25d429e4f3ecd1fb.0000\n",
      "upload: ../../../../../../var/folders/9h/1m96s7vn5z72cxt_q7g9p86h0000gn/T/predictive_object_KTxfse/d7c43331-ffdf-4089-b33c-e0cb57b6c91e/m_547fd4ded584a8dd/objects.bin to s3://gl-demo-usw2/predictive_service/demolab/ps-1.6/predictive_objects/pattern-mining/6/d7c43331-ffdf-4089-b33c-e0cb57b6c91e/m_547fd4ded584a8dd/objects.bin\n",
      "upload: ../../../../../../var/folders/9h/1m96s7vn5z72cxt_q7g9p86h0000gn/T/predictive_object_KTxfse/d7c43331-ffdf-4089-b33c-e0cb57b6c91e/m_547fd4ded584a8dd/m_63a1d80a9ff2ff08.0000 to s3://gl-demo-usw2/predictive_service/demolab/ps-1.6/predictive_objects/pattern-mining/6/d7c43331-ffdf-4089-b33c-e0cb57b6c91e/m_547fd4ded584a8dd/m_63a1d80a9ff2ff08.0000\n",
      "upload: ../../../../../../var/folders/9h/1m96s7vn5z72cxt_q7g9p86h0000gn/T/predictive_object_KTxfse/d7c43331-ffdf-4089-b33c-e0cb57b6c91e/m_547fd4ded584a8dd/m_63a1d80a9ff2ff08.frame_idx to s3://gl-demo-usw2/predictive_service/demolab/ps-1.6/predictive_objects/pattern-mining/6/d7c43331-ffdf-4089-b33c-e0cb57b6c91e/m_547fd4ded584a8dd/m_63a1d80a9ff2ff08.frame_idx\n",
      "upload: ../../../../../../var/folders/9h/1m96s7vn5z72cxt_q7g9p86h0000gn/T/predictive_object_KTxfse/d7c43331-ffdf-4089-b33c-e0cb57b6c91e/m_547fd4ded584a8dd/m_63a1d80a9ff2ff08.sidx to s3://gl-demo-usw2/predictive_service/demolab/ps-1.6/predictive_objects/pattern-mining/6/d7c43331-ffdf-4089-b33c-e0cb57b6c91e/m_547fd4ded584a8dd/m_63a1d80a9ff2ff08.sidx\n",
      "upload: ../../../../../../var/folders/9h/1m96s7vn5z72cxt_q7g9p86h0000gn/T/predictive_object_KTxfse/version to s3://gl-demo-usw2/predictive_service/demolab/ps-1.6/predictive_objects/pattern-mining/6/version\n",
      "upload: ../../../../../../var/folders/9h/1m96s7vn5z72cxt_q7g9p86h0000gn/T/predictive_object_KTxfse/d7c43331-ffdf-4089-b33c-e0cb57b6c91e/objects.bin to s3://gl-demo-usw2/predictive_service/demolab/ps-1.6/predictive_objects/pattern-mining/6/d7c43331-ffdf-4089-b33c-e0cb57b6c91e/objects.bin\n",
      "upload: ../../../../../../var/folders/9h/1m96s7vn5z72cxt_q7g9p86h0000gn/T/predictive_object_KTxfse/d7c43331-ffdf-4089-b33c-e0cb57b6c91e/m_25d429e4f3ecd1fb.frame_idx to s3://gl-demo-usw2/predictive_service/demolab/ps-1.6/predictive_objects/pattern-mining/6/d7c43331-ffdf-4089-b33c-e0cb57b6c91e/m_25d429e4f3ecd1fb.frame_idx\n",
      "Completed 16 of 17 part(s) with 1 file(s) remaining"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Successfully uploaded to s3 path s3://gl-demo-usw2/predictive_service/demolab/ps-1.6/predictive_objects/pattern-mining/6\n",
      "[INFO] Notifying: ec2-52-88-112-32.us-west-2.compute.amazonaws.com\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "upload: ../../../../../../var/folders/9h/1m96s7vn5z72cxt_q7g9p86h0000gn/T/predictive_object_KTxfse/pickle_archive to s3://gl-demo-usw2/predictive_service/demolab/ps-1.6/predictive_objects/pattern-mining/6/pickle_archive\n"
     ]
    }
   ],
   "source": [
    "ps.apply_changes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the model <a id='query'></a>\n",
    "\n",
    "You may do a test query before really deploying it to production. This will help detect errors in the function before deploying it the Predictive Service. \n",
    "\n",
    "<img src=\"images/right.png\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'from_cache': True,\n",
       " u'model': u'pattern-mining',\n",
       " u'response': [[u'ApricotDanish']],\n",
       " u'uuid': u'9a8aa339-0eec-4c4d-a713-be431fe1d098',\n",
       " u'version': 5}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test query to make sure the model works fine\n",
    "ps.query('pattern-mining', x={'Receipt': [1], 'StoreNum': [2], 'Item': ['CherryTart']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query from external applications via REST\n",
    "\n",
    "Now other applications can interact with our model! In the next section we will illustrate how to consume the model. We can also  use other APIs like ps.update() to update a mode, ps.remove() to remove a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model query is exposed through REST API. The path is:\n",
    "\n",
    "    http(s)://<your-ps-endpoint>/data/<model-name>\n",
    "    \n",
    "And the payload is a JSON serialized string in the following format:\n",
    "\n",
    "    {\"api_key\": <api key>,\n",
    "     \"data\": <data-passed-to-custom-query>}\n",
    "\n",
    "Here the 'api key' may be obtained through ps.api_key, and data is the actual data passed to the custom predictive object in the Predictive Service. It will be passed to the query using **kwargs format\n",
    "\n",
    "Here is a sample curl command to query your model:\n",
    "\n",
    "    curl -X POST -d '{\"api_key\":\"b437e588-0f2b-45e1-81c8-ce3acfa81ade\", \"data\":{\"x\":{\"Receipt\": [1], \"StoreNum\": [2], \"Item\": [\"CherryTart\"]}}}' http://demolab-one-six-2015364754.us-west-2.elb.amazonaws.com/query/pattern-mining\n",
    "   \n",
    "    \n",
    "You can also query though Python using the **requests module**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query through Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "def restful_query(x):\n",
    "    headers = {'content-type': 'application/json'}\n",
    "    payload = {'api_key':'b437e588-0f2b-45e1-81c8-ce3acfa81ade', \"data\":{\"x\": x}}\n",
    "    end_point = 'http://demolab-one-six-2015364754.us-west-2.elb.amazonaws.com/query/pattern-mining'\n",
    "    return requests.post(end_point, json.dumps(payload), headers=headers).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'from_cache': True,\n",
       " u'model': u'pattern-mining',\n",
       " u'response': [[u'ApricotDanish']],\n",
       " u'uuid': u'd8bab376-da23-4faa-af17-75e21462d3cf',\n",
       " u'version': 6}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restful_query({'Receipt': [1], 'StoreNum': [2], 'Item': ['CherryTart']})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
